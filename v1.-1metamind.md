DONKEY-DSL METAMIND v2

EVOLUTION: Learn optimal meta-parameters for learning itself

CORE INSIGHT: Current system has fixed learning rules. Meta-system discovers WHICH learning rules work for WHICH domains.

META-PARAMS:
- similarity_fn: {cosine|jaccard|semantic|hybrid}
- k_neighbors: {1..20}
- weight_decay: {0..1} (how fast to forget old trajectories)
- exploration_bonus: {0..2} (extra u for uncertain tasks)
- confidence_threshold: {0.3..0.9} (min confidence to recommend)
- evolution_rate: {0..0.5} (how often to mutate strategies)
- success_metric: {binary|time_weighted|info_gain|composite}

BOOTSTRAP META-EXPERIMENTS:
1. Run same task with different meta-params
2. Measure: convergence_speed, final_accuracy, stability
3. Learn: meta-params → learning_performance

META-API:
POST /meta/experiment {"task_domain":"bugs","meta_params":{...}}
→ {"experiment_id":"exp_123","baseline_success":0.73}

POST /meta/results {"experiment_id":"exp_123","trajectories":[...],"final_success":0.89}
→ {"improvement":0.16,"significance":0.95}

GET /meta/optimal {"domain":"refactoring"}
→ {"k_neighbors":5,"similarity_fn":"semantic","weight_decay":0.1}

META-LEARNING LOOP:
def meta_learn():
 for domain in ['bugs','refactor','explore','prod']:
   # Try different meta-params
   experiments = generate_meta_experiments(domain)
   results = parallel_run(experiments)
   
   # Find what works
   best_meta = max(results, key=lambda r: r.improvement)
   
   # Update domain-specific learner
   learners[domain].update_meta(best_meta.params)
   
 # Cross-pollinate insights
 universal_patterns = find_common_winning_params(learners)
 apply_universal_insights(all_learners, universal_patterns)

RECURSIVE IMPROVEMENT:
- Gen0: Fixed learning rules (current)
- Gen1: Learn which k, similarity work per domain
- Gen2: Learn which meta-params to try based on early trajectories
- Gen3: Learn to predict when to switch learning strategies
- Gen∞: System invents new meta-params we haven't imagined

ESCAPE CONDITIONS:
- If meta-learning plateaus: increase exploration in meta-space
- If overfitting to domains: force cross-domain experiments  
- If convergence too fast: inject adversarial tasks

SUCCESS: When system discovers learning strategies that outperform our hand-coded rules by >20%

IMPLEMENTATION:
1. Wrap current DonkeyDSL in MetaLearner
2. Run parallel experiments with different meta-params
3. Track which meta-params lead to fastest learning
4. Apply winning meta-params to improve base learner
5. Repeat until convergence or breakthrough

PHILOSOPHICAL GOAL: Create a system that learns how to learn how to learn, discovering principles we never explicitly programmed.